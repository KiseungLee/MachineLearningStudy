{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09-01\n",
    "\n",
    "Neural Nets으로 XOR 문제를 어떻게 풀었는지 설명해줄께\n",
    "\n",
    "1개의 유닛으론 XOR을 못푼다는게 수학적으로 증명이 됐었지\n",
    "\n",
    "그런데 2~3개의 유닛이 쓰인다면 어떻게 될까?\n",
    "\n",
    "일단 풀 순 있다.\n",
    "\n",
    "\n",
    "그런데 이런 의문도 있었음. 만약 풀수 있다고 해도 그 안쪽의 레이어들을 어떻게 학습시키냐 하는게 또 다른 의문 이었음.\n",
    "\n",
    "\n",
    "이번 강의에선 XOR을 푸는 방법에 대해 얘기해봄. \n",
    "\n",
    "\n",
    "이걸 3개의 유닛으로 풀어봄. \n",
    "\n",
    "각 유닛은 x1,x2를 받고 내부는 x1w1+x2w2+b로 이루어짐. 그리고 끝에 Sigmoid를 거쳐 1,0으로 나옴.\n",
    "\n",
    "일단 결론은 슬라이드에 있는 것 처럼 w, b를 잘 설정하면 3개의 유닛으로 XOR 을 구현할 수 있다. \n",
    "\n",
    "굳이... 내가 직접 안해봐도 되겠지\n",
    "\n",
    "\n",
    "이 3개의 유닛을 위와 같이 그려볼 수 있다. \n",
    "\n",
    "이 w, b 쌍은 엄청 많겠지\n",
    "\n",
    "\n",
    "그런데 우리 저번 강의들 중에서 위 그림처럼 두개의 네트워크를 행렬을 이용해 하나로 표현하는 방법을 배웠지.\n",
    "\n",
    "그래서 행렬로 묶어주면 위의 오른쪽 그림과 같이 깔끔하게 나타낼 수 있음. \n",
    "\n",
    "\n",
    "이걸 수식관계로 짜보면 위와 같음. 그리고 아래쪽에보면 코드는 저런식으로 더 쉽게 표현 가능. \n",
    "\n",
    "\n",
    "그럼 다시 처음의 질문들로 가보자. 일단 3개 유닛으로 XOR을 구현을 할 순 있었는데\n",
    "\n",
    "저걸 구하기 위해서 학습을 어떻게 시킬 것이냐!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bonus\n",
    "\n",
    "09-02 들어가기 전에 미분 특별 강의 해주심\n",
    "\n",
    "킹치만.. 다 아는 내용인걸..\n",
    "\n",
    "중첩된 함수 미분하는 것만 다시 좀 떠올리자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09-02\n",
    "\n",
    "중첩된 뒤쪽의 w, b를 어떻게 학습 시킬까\n",
    "\n",
    "안쪽의 x1의 최종 y에 대한 영향을 알아야 w를 조정하는데 계산량이 너무 많다. 수학적으로.\n",
    "\n",
    "수학적으론 가능하지. 중첩 함수를 미분하면 되니까.\n",
    "\n",
    "\n",
    "이걸 해결할 방법이 Backpropagation 기법임.\n",
    "\n",
    "예를들어 설명해줄게.\n",
    "\n",
    "g = wx\n",
    "f = wx+b = g+b\n",
    "\n",
    "일때 이 식을 그래프로 옮기면 다음과 같음.\n",
    "\n",
    "이 그래프에서 우리가 하고 싶은건 각각의 요소들이 최종 값에 미치는 영향력을 따지는 것임.\n",
    "\n",
    "\n",
    "중첩 함수를 미분할 땐 chain rule에 따라 바깥거 부터 미분 하고 ... 이거 알지\n",
    "\n",
    "\n",
    "\n",
    "2가지 스텝으로 나눠 진행함.\n",
    "\n",
    "1. forward : 그래프에 값을 넣어가며 최종 값들을 완성함\n",
    "\n",
    "2. backward : 미분 때리면서 뒤로 보냄. \n",
    "\n",
    "이건 손으로 직접 풀어봐도 좋을 거 같다. \n",
    "\n",
    "\n",
    "아 Back Propagation은 그냥 Chain rule로 미분하는거 그 자체였네. 별거 아니네. \n",
    "\n",
    "이건 슬라이드 보면서 손으로 한 번 따라해보는게 효과적이겠다. 따로 필기할 게 없네. \n",
    "\n",
    "\n",
    "\n",
    "지금까지 슬라이드는 그래도 간단한 구조였는데 만약 많이 중첩되어 있다면 어떻게 할까?\n",
    "\n",
    "그냥 차례차례 하면 됨 ㅋㅋ\n",
    "\n",
    "\n",
    "결국 Back propagation의 핵심은 하나네. Chain rule을 써서 안쪽의 미분값을 하나씩 구해나가는것.\n",
    "\n",
    "\n",
    "\n",
    "Sigmoid는 어떻게 미분할까? \n",
    "\n",
    "위처럼 그래프를 그려보면 쉬워진다. 단순하게 만들어서. \n",
    "\n",
    "\n",
    "\n",
    "그런데 이걸 텐서플로우를 사용한다면... 훨신쉽지. 그래프만 잘 만들어 놓으면 텐서플로가 알아서 해주니까. \n",
    "\n",
    "TensorBoard에서 그래프 만든거 볼 수 있는데 이번 lab에서 알려드림. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
